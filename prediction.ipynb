{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sparseml.pytorch.optim import ScheduledModifierManager\n",
    "from sparseml.pytorch.optim import ScheduledOptimizer\n",
    "from sparseml.pytorch.utils import get_prunable_layers\n",
    "from sparseml.pytorch.utils import tensor_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/neuralmagic/sparseml\n",
    "# !pip install -e \"sparseml[transformers]\"\n",
    "# !pip install sparseml\n",
    "# !wget https://huggingface.co/neuralmagic/TinyLlama-1.1B-Chat-v0.4-pruned50-quant-ds/raw/main/recipe.yaml\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is using in this ENV.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is using in this ENV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in ./myenv/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: coloredlogs in ./myenv/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.10/site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: flatbuffers in ./myenv/lib/python3.10/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.10/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in ./myenv/lib/python3.10/site-packages (from onnxruntime) (1.26.3)\n",
      "Requirement already satisfied: protobuf in ./myenv/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./myenv/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"./saved_model/sparse_model.onnx\"\n",
    "session = ort.InferenceSession(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Load Exported ONNX Model and Predict\n",
    "def load_and_predict_onnx_model(onnx_path, image, label):\n",
    "    import onnxruntime as ort\n",
    "\n",
    "    # Load the ONNX model\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "    # Prepare the input\n",
    "    image_np = image\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: image_np}\n",
    "\n",
    "    # Run the model\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    predicted_label = np.argmax(ort_outs[0])\n",
    "\n",
    "    result = {\n",
    "        \"Predicted as\" : predicted_label,\n",
    "        \"Ground Truth\" : label\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to predict an image from the test set\n",
    "image, label = testset[2]\n",
    "image = image.unsqueeze(0).to('cpu')\n",
    "# load_and_predict_onnx_model(onnx_path, image.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Predicted as': 1, 'Ground Truth': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function to predict\n",
    "load_and_predict_onnx_model(onnx_model_path, image.cpu().numpy(), label=label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
